{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "**Metamodels - models that take other models as input - then construct new models based on comparing the performance of the individual models**\n",
    "\n",
    "* They are often used by data scientist and machine learnng experts for optimising models\n",
    "* They are closely related to the concept of adaptive models\n",
    "\n",
    "Exercise\n",
    "Modify the name / gender classifier to make use of a meta model\n",
    "For every n construct a model that would classify on the last three letter as input, where:\n",
    "  * n ranges from 3\n",
    "  * total length of the name\n",
    "Your meta model will then compare the performance of each and pick the best model\n",
    "To make it meta, the model has to build the smaller versions itself\n",
    "    * Has to set the training and  data set\n",
    "    * Pick n\n",
    "    * Run it and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    '''builds dataset from NLTK corpus comprising male and female names.\n",
    "    returns list of tuples in form (name, sex) in random order\n",
    "    '''\n",
    "    male_names =  [name for name in names.words('male.txt')]\n",
    "    female_names =  [name for name in names.words('female.txt')]\n",
    "    model_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "    model_names = model_names + [(name, 'female') for name in names.words('female.txt')]\n",
    "    random.seed(0) # seed so can recreate results\n",
    "    random.shuffle(model_names)\n",
    "    return model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_dict(word, last_letters, word_length=0):\n",
    "    '''builds feature dict. \n",
    "    takes in word, number of last letters we are interested in and word length.\n",
    "    returns dictionary of features.\n",
    "    if word length is < the last letters parameter, as many last letters as possible will be included in the dict\n",
    "    if word length is 0 (i.e.false) or omitted, that feature will not be included'''\n",
    "    dict = {}\n",
    "    if len(word) < last_letters:\n",
    "        last_letters = len(word)\n",
    "    dict['last_letter(s)'] = word[-last_letters:]\n",
    "    if word_length:\n",
    "        dict['word_length'] = len(word)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_set(model_names, last_letters, word_length):\n",
    "    '''builds feature set.\n",
    "    takes in list of names, number of last letters we are interested in and word length.\n",
    "    returns a list of tuples in format (feature dict, sex), based on those names'''\n",
    "    return [(feature_dict(n, last_letters, word_length), g)for (n, g) in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(max_last_letters):\n",
    "    '''model takes parameter of max last letters to consider.\n",
    "    1/ builds dataset\n",
    "    2/ runs naive bayes. \n",
    "    Considering last number of letters up to max, on 2 bases:\n",
    "    -with name length\n",
    "    -without name length.\n",
    "    returns best model and its accuracy.\n",
    "    if dataset includes names shorter than the number of letters being considered, that cycle will be omitted \n",
    "    '''\n",
    "    model_names = build_dataset()\n",
    "    include_length = [0, 1]\n",
    "    score = 0\n",
    "    best = {}\n",
    "    for letter in range(1,max_last_letters+1): #here we exclude a no. of last letters if the data set includes longer names than that\n",
    "        if len([name for name in model_names if len(name) < letter]):\n",
    "            print('exclude {} letters - data set includes shorter names'.format(letter))\n",
    "            continue\n",
    "        print('last {} letters'.format(letter))\n",
    "        for setting in include_length:\n",
    "            if setting:\n",
    "                print('don\\'t include word length')\n",
    "            else:\n",
    "                print('include word length')\n",
    "            feature_set = build_feature_set(model_names, letter, setting)\n",
    "            train_set, test_set = feature_set[500:],feature_set[:500]\n",
    "            classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "            result = nltk.classify.accuracy(classifier, test_set)\n",
    "            print('result: {}'.format(result))\n",
    "            if result > score:\n",
    "                score = result\n",
    "                best['letters'] = letter\n",
    "                best['length on/off'] = bool(setting)\n",
    "    return(best, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last 1 letters\n",
      "include word length\n",
      "result: 0.768\n",
      "don't include word length\n",
      "result: 0.762\n",
      "last 2 letters\n",
      "include word length\n",
      "result: 0.818\n",
      "don't include word length\n",
      "result: 0.822\n",
      "exclude 3 letters - data set includes shorter names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'length on/off': True, 'letters': 2}, 0.822)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_2(max_last_letters):\n",
    "    '''model takes parameter of max last letters to consider.\n",
    "    1/ builds dataset\n",
    "    2/ runs naive bayes. \n",
    "    Considering last number of letters up to max, on 2 bases:\n",
    "    -with name length\n",
    "    -without name length.\n",
    "    returns best model and its accuracy.\n",
    "    this version relies on default behaviour of feature dict function - \n",
    "    if max last letters > number of letters in name, it will take the max possible letters for the feature dict\n",
    "    '''\n",
    "    model_names = build_dataset()\n",
    "    include_length = [0, 1]\n",
    "    score = 0\n",
    "    best = {}\n",
    "    for setting in include_length:\n",
    "        if setting:\n",
    "            print('don\\'t include word length')\n",
    "        else:\n",
    "            print('include word length')\n",
    "        for letter in range(1,max_last_letters+1):\n",
    "            print('last {} letters'.format(letter))\n",
    "            feature_set = build_feature_set(model_names, letter, setting)\n",
    "            train_set, test_set = feature_set[500:],feature_set[:500]\n",
    "            classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "            result = nltk.classify.accuracy(classifier, test_set)\n",
    "            print('result: {}'.format(result))\n",
    "            if result > score:\n",
    "                score = result\n",
    "                best['letters'] = letter\n",
    "                best['length on/off'] = bool(setting)\n",
    "    return(best, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include word length\n",
      "last 1 letters\n",
      "result: 0.768\n",
      "last 2 letters\n",
      "result: 0.818\n",
      "last 3 letters\n",
      "result: 0.768\n",
      "don't include word length\n",
      "last 1 letters\n",
      "result: 0.762\n",
      "last 2 letters\n",
      "result: 0.822\n",
      "last 3 letters\n",
      "result: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'length on/off': True, 'letters': 2}, 0.822)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
